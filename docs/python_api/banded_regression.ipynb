{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c006578c-6559-4f6a-b949-cb511a2ffb4b",
   "metadata": {},
   "source": [
    "# Banded ridge regression example\n",
    "\n",
    "In this example, we model fMRI responses in a Neuroscout dataset using *banded ridge regression*.\n",
    "\n",
    "Banded ridge regression allows you to fit and optimize a distinct regularization hyperparameters for each group or \"band\" of feature spaces. This is useful if you want to jointly fit two feature space sets. We can then also estimate the relative contribution of each feature set to our prediction for each voxel.\n",
    "\n",
    "This example assumes that you have already worked through the basic ridge regression example, which demonstrates how to use `pyns.fetch_utils` to retrieve Neuroscout predictor and neuroimaging data for model fitting.\n",
    "For a comprehensive tutorial, check out the excellent [voxelwise modeling tutorials](https://gallantlab.github.io/voxelwise_tutorials/index.html) from the Gallant Lab.\n",
    "\n",
    "__Note__: By implementing a custom pipeline, your analysis will not be centrally registered on neuroscout.org, and a reproducible record will not be made. For analyses supported the Neuroscout-CLI (e.g. group voxelwise mass univariate GLM models), it is recommended to use the neuroscout.org web inteface, or follow the guide for programmatically [creating analyses \n",
    "using pyNS](https://pyns.readthedocs.io/en/latest/analyses.html).\n",
    "\n",
    "### Citing Neuroscout\n",
    "\n",
    "If you publish any results using the Neuroscout data, be sure to cite the Neuroscout paper, and corresponding datasets:\n",
    "\n",
    "    Alejandro de la Vega, Roberta Rocca, Ross W Blair, Christopher J Markiewicz, Jeff Mentch, James D Kent, Peer Herholz, Satrajit S Ghosh, Russell A Poldrack, Tal Yarkoni (2022). *Neuroscout, a unified platform for generalizable and reproducible fMRI research*. eLife 11:e79277. https://doi.org/10.7554/eLife.79277\n",
    "    \n",
    "    Visconti di Oleggio Castello, M., Chauhan, V., Jiahui, G., & Gobbini, M. I. An fMRI dataset in response to “The Grand Budapest Hotel”, a socially-rich, naturalistic movie. Sci Data 7, 383 (2020). https://doi.org/10.1038/s41597-020-00735-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93540567-ff01-4fc2-985b-a055c0ab4927",
   "metadata": {},
   "source": [
    "If running this notebook on Google Colab, be sure to switch the runtime to GPU to expedite model ftting (Runtime -> Change runtime type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a23dd-6b1a-41c7-a0a1-828e4c0e8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1) Run once to install dependencies on Colab (pyNS, Datalad, and Machine Learning libraries) (~1 minute)\n",
    "%%capture --no-display --no-stderr\n",
    "from IPython.display import display\n",
    "display(\"Installing NeuroDebian...\")\n",
    "\n",
    "## Set up DataLad\n",
    "!wget -O- http://neuro.debian.net/lists/focal.us-ca.libre | sudo tee /etc/apt/sources.list.d/neurodebian.sources.list && sudo apt-key adv --recv-keys --keyserver hkps://keyserver.ubuntu.com 0xA5D32F012649A5A9 && sudo apt-get update\n",
    "display(\"Installing DataLad...\")\n",
    "\n",
    "!sudo apt-get install datalad -y\n",
    "%pip install -U datalad\n",
    "!git config --global user.email \"you@example.com\" && git config --global user.name \"Your Name\"\n",
    "\n",
    "display(\"Installing PyNS...\")\n",
    "%pip install pyns\n",
    "%pip install git+https://github.com/bids-standard/pybids.git#egg=pybids\n",
    "\n",
    "display(\"Installing analysis dependencies (nilearn, and himalaya)...\")\n",
    "%pip install nilearn himalaya\n",
    "\n",
    "display(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a27d22-1538-4a1c-b243-390e548dd16a",
   "metadata": {},
   "source": [
    "## Fetching Neuroscout Data\n",
    "\n",
    "For this example, we'll build on our previous example, and focus on a single subject from the `Budapest` dataset, in which subjects watched the movie \"The Grand Budapest Hotel\".\n",
    "\n",
    "See the previous example to learn how to browse which datasets and features are available.\n",
    "\n",
    "First, we define the dataset name, and subject we want to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf504ab-2446-4b4c-bf5a-204dc9d740eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Budapest'\n",
    "subject = 'sid000005'\n",
    "runs = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ceb86-debe-41a0-90a9-6650601e5256",
   "metadata": {},
   "source": [
    "Next we define the names of the features we want to analyze.\n",
    "\n",
    "We will fetch two sets of predictors: [Mel spetrogram](https://neuroscout.org/predictor/mel_0), and  [Mel Frequency Cepstral Coefficient (MFCC)](https://neuroscout.org/predictor/mfcc_0).\n",
    "\n",
    "In addition, we will also fetch 7 nuisance regressors: `framewise_displacement`, `trans_x`, `trans_y`, `trans_z`, `rot_x`, and `rot_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e39400-4b75-46f0-818d-5ec0541ead0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = [f'mfcc_{i}' for i in range(20)]\n",
    "mel = [f'mel_{i}' for i in range(64)]\n",
    "confounds = ['rot_x', 'rot_y', 'rot_z', 'trans_x', 'trans_y', 'trans_z']\n",
    "\n",
    "all_vars = mfccs + mel + confounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce6878d-8410-430f-9021-26cd8c69cf5c",
   "metadata": {},
   "source": [
    "Next, we'll use `pyns.fetch_predictors` to retrieve these predictors for the target subject, rescale to unit variance, and resampl to the imaging data's Repetition Time (TR).\n",
    "\n",
    "Since downloading and resampling can take a minute, for this example we'll only use the first three (out of 8) runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3333437-30ba-4235-be21-b68849f78c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/miniconda3/envs/nsencoding/lib/python3.10/site-packages/pyns/endpoints/base.py:135: UserWarning: No API endpoint for stimulus_id, could not convert\n",
      "  warnings.warn(f\"No API endpoint for {col}, could not convert\")\n"
     ]
    }
   ],
   "source": [
    "from pyns.fetch_utils import fetch_predictors, fetch_images\n",
    "\n",
    "predictors = fetch_predictors(all_vars, dataset_name=dataset_name, subject=subject, run=runs, rescale=True, resample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8ed792-4d03-400f-b1f2-f05d11a16d62",
   "metadata": {},
   "source": [
    "Finally, we load the corresponding images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba32fc2e-1694-43b9-95f9-dec0a42ba69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/miniconda3/envs/nsencoding/lib/python3.10/site-packages/bids/layout/validation.py:48: UserWarning: The ability to pass arguments to BIDSLayout that control indexing is likely to be removed in future; possibly as early as PyBIDS 0.14. This includes the `config_filename`, `ignore`, `force_index`, and `index_metadata` arguments. The recommended usage pattern is to initialize a new BIDSLayoutIndexer with these arguments, and pass it to the BIDSLayout via the `indexer` argument.\n",
      "  warnings.warn(\"The ability to pass arguments to BIDSLayout that control \"\n",
      "/home/alejandro/miniconda3/envs/nsencoding/lib/python3.10/site-packages/bids/layout/validation.py:122: UserWarning: The PipelineDescription field was superseded by GeneratedBy in BIDS 1.4.0. You can use ``pybids upgrade`` to update your derivative dataset.\n",
      "  warnings.warn(\"The PipelineDescription field was superseded \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action summary:\n",
      "  get (notneeded: 6)\n"
     ]
    }
   ],
   "source": [
    "# Note: This command can hang after fetching images. \n",
    "# If so, stop this cell and re-run, and it will immediately re-execute\n",
    "preproc_dir, img_objs = fetch_images('Budapest', '/tmp/', subject=subject, run=runs, fetch_brain_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d21d16-4410-4bc2-98c9-2b670f8b5a4b",
   "metadata": {},
   "source": [
    "## Preprocessing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81f6a8-cf07-4b48-b714-76bd27e38ead",
   "metadata": {},
   "source": [
    "As in the last example, we will:\n",
    "\n",
    "1) Compute a joint mask between all runs\n",
    "2) Mask images and stack all runs into a single array.\n",
    "\n",
    "Note that you could choose to use a different mask, or prepare data for analysis in a different way if you so choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc5e383-aa1e-4fb8-a395-c3f8db205cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/miniconda3/envs/nsencoding/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3442: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Separate bold images from masks\n",
    "all_funcs = [f for f in img_objs if f.entities['suffix'] == 'bold']\n",
    "all_masks = [f for f in img_objs if f.entities['suffix'] == 'mask']\n",
    "\n",
    "# Compute joint mask\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "def _compute_mask_intersection(masks): \n",
    "    \"\"\" Compute joint masks (i.e. where all masks have 1s)\"\"\"\n",
    "    _masks = [nib.load(m) for m in masks]\n",
    "    _data = np.stack(n.get_fdata() for n in _masks)\n",
    "    \n",
    "    intersection = _data.min(axis=0)\n",
    "    \n",
    "    mask = nib.Nifti1Image(\n",
    "        intersection, affine = _masks[0].affine, header=_masks[0].header)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "inter_mask = _compute_mask_intersection(all_masks)\n",
    "\n",
    "# Mask images and stack into a single array\n",
    "import pandas as pd\n",
    "from nilearn.maskers import NiftiMasker\n",
    "\n",
    "def _mask_and_stack_images(image_objects, mask):\n",
    "    \"\"\" Stack images into single array, and collect metadata entities into DataFrame \"\"\"\n",
    "    masker = NiftiMasker(mask_img=mask)\n",
    "\n",
    "    arrays = []\n",
    "    entities = []\n",
    "    image_objects = sorted(image_objects, key=lambda x: x.entities['run'])\n",
    "    for img in image_objects:\n",
    "        run_y = masker.fit_transform(img)\n",
    "        arrays.append(run_y)\n",
    "        entities += [dict(img.entities)] * run_y.shape[0]\n",
    "    entities = pd.DataFrame(entities)\n",
    "    return np.vstack(arrays), entities, masker\n",
    "\n",
    "y, img_entities, masker = _mask_and_stack_images(all_funcs, inter_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4db050-7b3b-4db1-9948-14eba259770e",
   "metadata": {},
   "source": [
    "The stacked runs have shape: `(n_volumes, n_voxels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "061a3d7d-3729-48d2-bac4-93e2259929a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1631, 124614)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0aa89-54df-4e07-bed1-cdd5957fc220",
   "metadata": {},
   "source": [
    "## Fitting a banded (or grouped) ridge regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181ada1-bd37-4cf6-9b3a-9475abba530c",
   "metadata": {},
   "source": [
    "To fit both Mel spectrogram and MFCC features jointly in the same run, we must modify our previous workflow to have the concept of \"bands\", or groups of features.\n",
    "\n",
    "The following workflow assumes a single pandas DataFrame that includes all of the features (`X_vars`). For a banded model, you additionally need to specify `bands` which is a list of lists, where each sublist contains the names of the features in that band.\n",
    "\n",
    "In this example, we will use the Mel spectrogram features as the first band, and the MFCC features as the second band.\n",
    "\n",
    "In addition, we can specify a list of `confounds` to be included in the model, but not used for prediction. This is useful if you want to include nuisance regressors in the model, but not use them to predict voxelwise activity.\n",
    "\n",
    "Finally, the `split` parameter allows us to adjust model scores in such a way to to disentangle the contribution of the two feature spaces. Split scoring computes the prediction for each feature space separately, and corrects the resulting scores so that the sum of scores from distinct feature spaces sum to the scores of the full prediction. This can be helpful to understand which feature space is *better* at predicting activity in a given voxel. \n",
    "\n",
    "To learn more, please see the [banded ridge regression example](https://gallantlab.org/voxelwise_tutorials/_auto_examples/shortclips/06_plot_banded_ridge_model.html#sphx-glr-auto-examples-shortclips-06-plot-banded-ridge-model-py) in the Gallant lab voxlelwise modeling tutorials.\n",
    "\n",
    "The following working `_model_cv` expands on the previous example with the addition of the `bands`, `split` and `confounds` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9637425-faec-4f83-9e36-cf0630e64103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from himalaya.scoring import correlation_score\n",
    "\n",
    "def _model_cv(estimator, cv, X_vars, y, bands=None, confounds=None,groups=None,\n",
    "    scoring=correlation_score, split=True, inner_cv=None):\n",
    "    \"\"\" Cross-validate a model on a set of variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : Scikit-learn like estimator\n",
    "        Estimator to use for fitting the model. Must have a fit and predict\n",
    "        method.\n",
    "    cv : cross-validation generator or an iterable\n",
    "        Outer cross-validation generator to use for cross-validation.\n",
    "    X_vars : pandas.DataFrame\n",
    "        Dataframe containing the variables to use for prediction.\n",
    "    y : array-like, shape (n_samples, n_targets)\n",
    "        Target values.\n",
    "    bands : list of str, optional\n",
    "        List of bands to use for prediction. If None, all of X_vars will be\n",
    "        used.\n",
    "    confounds : list of str, optional\n",
    "        List of confounds to use for prediction. Confounds will be removed\n",
    "        from the model coefficients prior to scoring.\n",
    "    groups : array-like, with shape (n_samples,), optional\n",
    "        Group labels for the samples used while splitting the dataset into\n",
    "        train/test set.\n",
    "    scoring : callable, optional  (default: correlation_score)\n",
    "        Scoring function to use for evaluating the model.\n",
    "    split : bool, optional (default: True)\n",
    "        If True, the prediction will be split by band.\n",
    "    inner_cv : cross-validation generator or an iterable, optional\n",
    "        Inner cross-validation generator to use for cross-validation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Container for results\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    if bands is not None:\n",
    "        X = []\n",
    "        for band in bands:\n",
    "            X.append(X_vars[band].values)\n",
    "\n",
    "        # If confounds, stack at the end\n",
    "        if confounds is not None:\n",
    "            bands.append(confounds)\n",
    "    else:\n",
    "        X = X_vars.as_matrix()\n",
    "\n",
    "        if confounds is not None:\n",
    "            X = np.hstack([X, confounds])\n",
    "\n",
    "    # Extract data from dataframe\n",
    "    X = X_vars.values\n",
    "\n",
    "    # Extract number of samples for convenience\n",
    "    n_samples = y.shape[0]\n",
    "\n",
    "    # Loop through outer cross-validation folds\n",
    "    for train, test in cv.split(np.arange(n_samples), groups=groups):\n",
    "        \n",
    "        # Get training model for list of model bands\n",
    "        \n",
    "        X_train = [x[train] for x in X] if type(X) == list else X[train]\n",
    "        X_test = [x[test] for x in X] if type(X) == list else X[test]\n",
    "        \n",
    "        # Create inner cross-validation loop if specified\n",
    "        if inner_cv:\n",
    "            # Split inner cross-validation with groups if supplied\n",
    "            inner_groups = np.array(groups)[train] if groups else groups\n",
    "            inner_splits = inner_cv.split(np.arange(n_samples)[train],\n",
    "                                            groups=inner_groups)\n",
    "            \n",
    "            # Update estimator with inner cross-validator\n",
    "            estimator.set_params(cv=inner_splits)\n",
    "\n",
    "        # Fit the regression model on training data\n",
    "        estimator.fit(X_train, y[train])\n",
    "\n",
    "        # Zero out coefficients for confounds if provided\n",
    "        if confounds is not None:\n",
    "            estimator.dual_coef_[-len(confounds):] = 0\n",
    "    \n",
    "        # Compute predictions with optional splitting by band\n",
    "        kwargs = {}\n",
    "        if split is not None:\n",
    "            kwargs['split'] = split\n",
    "\n",
    "        test_prediction = estimator.predict(X_test, **kwargs)\n",
    "        \n",
    "        # Test scores\n",
    "        test_score = scoring(y[test], test_prediction)\n",
    "        \n",
    "        # Test scores\n",
    "        test_score = scoring(y[test], test_prediction)\n",
    "\n",
    "        # If output is not an array, assume its a torch Tensor and convert to array\n",
    "        if not isinstance(test_prediction, np.ndarray):\n",
    "            test_prediction = test_prediction.cpu().numpy()\n",
    "            test_score = test_score.cpu().numpy()\n",
    "            \n",
    "        # Populate results dictionary\n",
    "        results['test_predictions'].append(test_prediction)\n",
    "        results['test_scores'].append(test_score)\n",
    "        \n",
    "        \n",
    "    # Combine into single aray\n",
    "    results['test_scores'] = np.stack(results['test_scores'])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fd874-94bc-449c-a1c5-846a247b49f0",
   "metadata": {},
   "source": [
    "### Mel spectrogram features and MFCC features are jointly fit in the same model\n",
    "\n",
    "Here, we will fit a banded ridge regression model, where the Mel spectrogram features and MFCC features are jointly fit in the same model. In addition, we will include a set of nuisance regressors in the model (6 motion parameters), but not use them to predict voxelwise activity.\n",
    "\n",
    "First, we will instantiate the `MultipleKernelRidgeCV` estimator, cross-validation strategy (leave one run out), and extract the group labels for each observation (i.e. the run number). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454bbe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alejandro/miniconda3/envs/nsencoding/lib/python3.10/site-packages/himalaya/backend/_utils.py:56: UserWarning: Setting backend to torch_cuda failed: PyTorch with CUDA is not available..Falling back to numpy backend.\n",
      "  warnings.warn(f\"Setting backend to {backend} failed: {str(error)}.\"\n"
     ]
    }
   ],
   "source": [
    "from himalaya.kernel_ridge import MultipleKernelRidgeCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from himalaya.scoring import correlation_score_split\n",
    "from himalaya.backend import set_backend\n",
    "\n",
    "backend = set_backend(\"torch_cuda\", on_error=\"warn\")\n",
    "\n",
    "groups = predictors['run'].tolist()\n",
    "\n",
    "# Set up estimator and CV objects\n",
    "estimator = MultipleKernelRidgeCV()\n",
    "n_runs = len(set(groups))\n",
    "cv = GroupKFold(n_splits=n_runs)\n",
    "inner_cv = GroupKFold(n_splits=n_runs - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a4504",
   "metadata": {},
   "source": [
    "Next, we will fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0797d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[........................................] 100% | 152.05 sec | 100 random sampling with cv | \n",
      "[........................................] 100% | 151.95 sec | 100 random sampling with cv | \n",
      "[........................................] 100% | 163.35 sec | 100 random sampling with cv | \n",
      "[......................................  ] 96% | 254.81 sec | 100 random sampling with cv | "
     ]
    }
   ],
   "source": [
    "# Set up X variables (i.e. only predictor columns, no meta-data)\n",
    "X = predictors.drop(['run', 'run_id', 'subject', 'onset', 'duration'], axis=1)\n",
    "\n",
    "results_combined = _model_cv(\n",
    "    estimator, cv, X, y, bands=[mfccs, mel], confounds=confounds, inner_cv=inner_cv, groups=groups\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c311581-95ec-4e2f-a0e1-2d8e663d4660",
   "metadata": {},
   "source": [
    "Warning: Model fiting may not succeed without sufficient RAM (i.e. free Google Colab GPU Runtime). \n",
    "\n",
    "Apply a more restrictive spatial mask (in `_mask_and_stack_images`) or run on a more powerful machine (upgrade Google Colab, or run on a local GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d5934",
   "metadata": {},
   "source": [
    "The `test_scores` and coefficients are of shape: `(n_folds, n_voxels)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd247fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 124614)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_combined['test_scores'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe6ad8",
   "metadata": {},
   "source": [
    "We can now average across folds to get the mean scores for each band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "319088bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_combined = results_combined['test_scores'].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e605c0",
   "metadata": {},
   "source": [
    "A model with both MFCC and mel-spectrogram perform potentially better than either model alone. This is because the two feature spaces are capturing different aspects of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94289a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48470750769353477"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_combined.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0009d03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016417411444655815"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_combined.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad79bd7",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "\n",
    "The goal of this tutorial is to demonstrate how a banded regression model can be fit using `pyns.fetch_utils` and `himalaya. \n",
    "\n",
    "For a more comprehensive tutorial, check out the excellent [voxelwise modeling tutorials](https://gallantlab.github.io/voxelwise_tutorials/index.html) from the Gallant Lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc333b",
   "metadata": {},
   "source": [
    "# Citing Neuroscout\n",
    "Please ensure to cite Neuroscout if publishing any work using these data, and be aware that there are ongoing efforts to standardize the most common variations of voxel-wise encoding models, in order to enable users to fully specify and register their analysis in Neuroscout (like you currently can for summary-statistics multi-level GLM models). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
